{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import logging\n",
    "\n",
    "# Cấu hình logging cơ bản\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 22:31:01,923 - INFO - Loading credits data...\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Loading credits data...\")\n",
    "data = pd.read_csv('datasets/credits.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 22:31:08,558 - INFO - Loading metadata...\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Loading metadata...\")\n",
    "meta = pd.read_csv('datasets/movie_metadata.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 22:31:11,063 - INFO - Processing release dates...\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Processing release dates...\")\n",
    "meta['year'] = meta['title_year']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_json_data(df, columns):\n",
    "    \"\"\"\n",
    "    Kiểm tra tính hợp lệ của dữ liệu JSON trong các cột được chỉ định\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame cần kiểm tra\n",
    "        columns (list): Danh sách các cột cần validate\n",
    "        \n",
    "    Returns:\n",
    "        dict: Kết quả validate cho mỗi cột\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            total = len(df[col])\n",
    "            valid_json = 0\n",
    "            invalid_json = 0\n",
    "            empty_json = 0\n",
    "            \n",
    "            for item in df[col]:\n",
    "                if pd.isna(item) or item == '':\n",
    "                    empty_json += 1\n",
    "                else:\n",
    "                    try:\n",
    "                        # Thử parse JSON string\n",
    "                        ast.literal_eval(item)\n",
    "                        valid_json += 1\n",
    "                    except:\n",
    "                        invalid_json += 1\n",
    "            \n",
    "            # Log kết quả\n",
    "            logging.info(f\"\\n{col}:\")\n",
    "            logging.info(f\"  Valid JSON: {valid_json}\")\n",
    "            logging.info(f\"  Invalid JSON: {invalid_json}\")\n",
    "            logging.info(f\"  Empty JSON: {empty_json}\")\n",
    "            logging.info(f\"  Validity rate: {(valid_json/total*100):.2f}%\")\n",
    "            \n",
    "            results[col] = {\n",
    "                'valid': valid_json,\n",
    "                'invalid': invalid_json,\n",
    "                'empty': empty_json,\n",
    "                'total': total\n",
    "            }\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 22:49:42,511 - INFO - Loading data files...\n",
      "2025-06-12 22:49:46,012 - INFO - === DATASET INFORMATION ===\n",
      "2025-06-12 22:49:46,013 - INFO - Credits shape: (45476, 3)\n",
      "2025-06-12 22:49:46,014 - INFO - Metadata shape: (5043, 28)\n",
      "2025-06-12 22:49:46,015 - INFO - Processing release dates...\n",
      "2025-06-12 22:50:07,160 - INFO - \n",
      "cast:\n",
      "2025-06-12 22:50:07,161 - INFO -   Valid JSON: 45476\n",
      "2025-06-12 22:50:07,162 - INFO -   Invalid JSON: 0\n",
      "2025-06-12 22:50:07,163 - INFO -   Empty JSON: 0\n",
      "2025-06-12 22:50:07,164 - INFO -   Validity rate: 100.00%\n",
      "2025-06-12 22:50:24,003 - INFO - \n",
      "crew:\n",
      "2025-06-12 22:50:24,004 - INFO -   Valid JSON: 45476\n",
      "2025-06-12 22:50:24,004 - INFO -   Invalid JSON: 0\n",
      "2025-06-12 22:50:24,004 - INFO -   Empty JSON: 0\n",
      "2025-06-12 22:50:24,005 - INFO -   Validity rate: 100.00%\n",
      "2025-06-12 22:50:24,006 - INFO - \n",
      "=== YEAR DISTRIBUTION ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "year\n",
       "1916.0      1\n",
       "1920.0      1\n",
       "1925.0      1\n",
       "1927.0      1\n",
       "1929.0      2\n",
       "         ... \n",
       "2012.0    221\n",
       "2013.0    237\n",
       "2014.0    252\n",
       "2015.0    226\n",
       "2016.0    106\n",
       "Name: count, Length: 91, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 22:50:24,009 - INFO - Filtering 2017 movies...\n",
      "2025-06-12 22:50:24,012 - INFO - Merging datasets...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'movie_title'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_2352\\2921469772.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     25\u001b[39m new_meta = meta.loc[meta.year == \u001b[32m2017\u001b[39m, [\u001b[33m'genres'\u001b[39m, \u001b[33m'movie_title'\u001b[39m, \u001b[33m'title_year'\u001b[39m]]\n\u001b[32m     26\u001b[39m \n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Merge dữ liệu\u001b[39;00m\n\u001b[32m     28\u001b[39m logging.info(\u001b[33m\"Merging datasets...\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m data = pd.merge(new_meta, credits, on=\u001b[33m'movie_title'\u001b[39m)\n\u001b[32m     30\u001b[39m pd.set_option(\u001b[33m'display.max_colwidth'\u001b[39m, \u001b[32m75\u001b[39m)\n\u001b[32m     31\u001b[39m \n\u001b[32m     32\u001b[39m logging.info(\u001b[33m\"\\n=== MERGED DATA INFORMATION ===\"\u001b[39m)\n",
      "\u001b[32md:\\MovieRecommendationSystem\\movie_recommender_env\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    166\u001b[39m             validate=validate,\n\u001b[32m    167\u001b[39m             copy=copy,\n\u001b[32m    168\u001b[39m         )\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m         op = _MergeOperation(\n\u001b[32m    171\u001b[39m             left_df,\n\u001b[32m    172\u001b[39m             right_df,\n\u001b[32m    173\u001b[39m             how=how,\n",
      "\u001b[32md:\\MovieRecommendationSystem\\movie_recommender_env\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[39m\n\u001b[32m    790\u001b[39m             self.right_join_keys,\n\u001b[32m    791\u001b[39m             self.join_names,\n\u001b[32m    792\u001b[39m             left_drop,\n\u001b[32m    793\u001b[39m             right_drop,\n\u001b[32m--> \u001b[39m\u001b[32m794\u001b[39m         ) = self._get_merge_keys()\n\u001b[32m    795\u001b[39m \n\u001b[32m    796\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m left_drop:\n\u001b[32m    797\u001b[39m             self.left = self.left._drop_labels_or_levels(left_drop)\n",
      "\u001b[32md:\\MovieRecommendationSystem\\movie_recommender_env\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1293\u001b[39m                         \u001b[38;5;66;03m# Then we're either Hashable or a wrong-length arraylike,\u001b[39;00m\n\u001b[32m   1294\u001b[39m                         \u001b[38;5;66;03m#  the latter of which will raise\u001b[39;00m\n\u001b[32m   1295\u001b[39m                         rk = cast(Hashable, rk)\n\u001b[32m   1296\u001b[39m                         \u001b[38;5;28;01mif\u001b[39;00m rk \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1297\u001b[39m                             right_keys.append(right._get_label_or_level_values(rk))\n\u001b[32m   1298\u001b[39m                         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1299\u001b[39m                             \u001b[38;5;66;03m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[32m   1300\u001b[39m                             right_keys.append(right.index._values)\n",
      "\u001b[32md:\\MovieRecommendationSystem\\movie_recommender_env\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1907\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1908\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1909\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1910\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1912\u001b[39m \n\u001b[32m   1913\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1914\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'movie_title'"
     ]
    }
   ],
   "source": [
    "# Load và xử lý dữ liệu ban đầu\n",
    "logging.info(\"Loading data files...\")\n",
    "credits = pd.read_csv('datasets/credits.csv')\n",
    "meta = pd.read_csv('datasets/movie_metadata.csv')\n",
    "\n",
    "logging.info(\"=== DATASET INFORMATION ===\")\n",
    "logging.info(f\"Credits shape: {credits.shape}\")\n",
    "logging.info(f\"Metadata shape: {meta.shape}\")\n",
    "\n",
    "# Xử lý năm phát hành\n",
    "logging.info(\"Processing release dates...\")\n",
    "meta['year'] = meta['title_year']\n",
    "\n",
    "# Validate JSON columns trong credits dataset\n",
    "json_columns = ['cast', 'crew']  # Chỉ validate cast và crew vì genres nằm trong meta\n",
    "validation_results = validate_json_data(credits, json_columns)\n",
    "\n",
    "# Hiển thị phân bố theo năm\n",
    "logging.info(\"\\n=== YEAR DISTRIBUTION ===\")\n",
    "year_dist = meta['year'].value_counts().sort_index()\n",
    "display(year_dist)\n",
    "\n",
    "# Lọc phim 2017 - giữ nguyên logic gốc\n",
    "logging.info(\"Filtering 2017 movies...\")\n",
    "new_meta = meta.loc[meta.year == 2017, ['genres', 'movie_title', 'title_year']]\n",
    "\n",
    "# Merge dữ liệu\n",
    "logging.info(\"Merging datasets...\")\n",
    "data = pd.merge(new_meta, credits, on='movie_title')\n",
    "pd.set_option('display.max_colwidth', 75)\n",
    "\n",
    "logging.info(\"\\n=== MERGED DATA INFORMATION ===\")\n",
    "logging.info(f\"Shape after merge: {data.shape}\")\n",
    "display(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta['year'] = meta['release_date'].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta['year'].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting only 2017 movies as we already have movies up to the year 2016 in preprocessing 1 file. \n",
    "# We don't have enough data for the movies from 2018, 2019 and 2020. \n",
    "# We'll deal with it in the upcoming preprocessing files\n",
    "logging.info(\"Filtering 2017 movies...\")\n",
    "new_meta = meta.loc[meta.year == 2017, ['genres', 'id', 'title', 'year']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_meta['id'] = new_meta['id'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Merging datasets...\")\n",
    "data = pd.merge(new_meta, credits, on='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 75)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluates an expression node or a string containing a Python literal or container display\n",
    "logging.info(\"Parsing JSON data...\")\n",
    "data['genres'] = data['genres'].map(lambda x: ast.literal_eval(x))\n",
    "data['cast'] = data['cast'].map(lambda x: ast.literal_eval(x))\n",
    "data['crew'] = data['crew'].map(lambda x: ast.literal_eval(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_genresList(x):\n",
    "    gen = []\n",
    "    st = \" \"\n",
    "    for i in x:\n",
    "        if i.get('name') == 'Science Fiction':\n",
    "            scifi = 'Sci-Fi'\n",
    "            gen.append(scifi)\n",
    "        else:\n",
    "            gen.append(i.get('name'))\n",
    "    if gen == []:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return (st.join(gen))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Creating genres list...\")\n",
    "data['genres_list'] = data['genres'].map(lambda x: make_genresList(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor1(x):\n",
    "    casts = []\n",
    "    for i in x:\n",
    "        casts.append(i.get('name'))\n",
    "    if casts == []:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return (casts[0])\n",
    "\n",
    "def get_actor2(x):\n",
    "    casts = []\n",
    "    for i in x:\n",
    "        casts.append(i.get('name'))\n",
    "    if casts == [] or len(casts)<=1:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return (casts[1])\n",
    "\n",
    "def get_actor3(x):\n",
    "    casts = []\n",
    "    for i in x:\n",
    "        casts.append(i.get('name'))\n",
    "    if casts == [] or len(casts)<=2:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return (casts[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Extracting actor information...\")\n",
    "data['actor_1_name'] = data['cast'].map(lambda x: get_actor1(x))\n",
    "data['actor_2_name'] = data['cast'].map(lambda x: get_actor2(x))\n",
    "data['actor_3_name'] = data['cast'].map(lambda x: get_actor3(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directors(x):\n",
    "    dt = []\n",
    "    st = \" \"\n",
    "    for i in x:\n",
    "        if i.get('job') == 'Director':\n",
    "            dt.append(i.get('name'))\n",
    "    if dt == []:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return (st.join(dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Extracting director information...\")\n",
    "data['director_name'] = data['crew'].map(lambda x: get_directors(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Preparing final dataset...\")\n",
    "movie = data.loc[:, ['director_name', 'actor_1_name', 'actor_2_name', 'actor_3_name', 'genres_list', 'title']]\n",
    "movie = movie.dropna(how='any')\n",
    "\n",
    "# Đổi tên cột\n",
    "movie = movie.rename(columns={'genres_list': 'genres'})\n",
    "movie = movie.rename(columns={'title': 'movie_title'})\n",
    "\n",
    "# Chuyển tên phim về chữ thường\n",
    "movie['movie_title'] = movie['movie_title'].str.lower()\n",
    "\n",
    "# Tạo cột combined features\n",
    "movie['comb'] = movie['actor_1_name'] + ' ' + movie['actor_2_name'] + ' ' + movie['actor_3_name'] + ' ' + movie['director_name'] + ' ' + movie['genres']\n",
    "\n",
    "# Load dữ liệu cũ và merge\n",
    "logging.info(\"Loading and processing old data...\")\n",
    "old = pd.read_csv('data.csv')\n",
    "old['comb'] = old['actor_1_name'] + ' ' + old['actor_2_name'] + ' ' + old['actor_3_name'] + ' ' + old['director_name'] + ' ' + old['genres']\n",
    "\n",
    "# Lưu kết quả\n",
    "logging.info(\"Saving results...\")\n",
    "movie.to_csv('new_data.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie_recommender_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
